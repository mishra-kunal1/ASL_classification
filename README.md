# ASL_classification_pytorch

### Signs Speak Louder Than Words
Developing an Image Recognition Model for American Sign Language (ASL)
The ability to communicate effectively is an essential aspect of human existence, yet it remains a challenge for individuals who
experience hearing or verbal impairments.  
The aim of the project is to train a model to recognize sign language in real time, using a webcam as the input source. 

Here's the medium blog for this repo - [Blog link](https://medium.com/@kunalmishra78/signs-speak-louder-than-words-de0197780c95)

Dataset Used - [ASL Alphabet](https://www.kaggle.com/datasets/grassknoted/asl-alphabet)

The code can be extended to perform image classification on any dataset by just modifying the path and number of classes.

``` diff
+ Please follow below instructions to run the code
- Change the dataset path in main.py 
- pip intall -r requirements.txt
- python main.py
- python inference.py (to predict the images from webcam)
```

Here's the results



![ezgif com-video-to-gif](https://user-images.githubusercontent.com/99056351/220795800-0eb0d3f9-cb83-4ee0-861f-ddbb766a6702.gif)
